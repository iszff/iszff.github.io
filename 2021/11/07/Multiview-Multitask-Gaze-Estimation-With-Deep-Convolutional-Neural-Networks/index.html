<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Multiview Multitask Gaze Estimation With Deep Convolutional Neural Networks | iszff&#39; Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="2018 TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS Dongze Lian, Lina Hu, Weixin Luo, Y anyu Xu, Lixin Duan, Jingyi Y u,Member , IEEE, and Shenghua Gao.  (1) 评价：基于深度卷积神经网络的多视图多任务注视估计 (2)  针对问题：">
<meta property="og:type" content="article">
<meta property="og:title" content="Multiview Multitask Gaze Estimation With Deep Convolutional Neural Networks">
<meta property="og:url" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/index.html">
<meta property="og:site_name" content="iszff&#39; Blog">
<meta property="og:description" content="2018 TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS Dongze Lian, Lina Hu, Weixin Luo, Y anyu Xu, Lixin Duan, Jingyi Y u,Member , IEEE, and Shenghua Gao.  (1) 评价：基于深度卷积神经网络的多视图多任务注视估计 (2)  针对问题：">
<meta property="og:locale">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211107213710618.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211112160847091.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/mmcodeStruct.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211116170548765.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211116170844442.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211116171147547.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211116172803224.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/%E5%AE%9E%E9%AA%8C%E5%8F%82%E6%95%B0.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211116212707500.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211117164429587.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks%5CSTpy_101th_row.png">
<meta property="og:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211119155759306.png">
<meta property="article:published_time" content="2021-11-07T01:52:13.000Z">
<meta property="article:modified_time" content="2021-11-19T09:08:19.838Z">
<meta property="article:author" content="iszff">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users/iszha/AppData/Roaming/Typora/typora-user-images/image-20211107213710618.png">
  
    <link rel="alternate" href="/atom.xml" title="iszff&#39; Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">iszff&#39; Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/" class="article-date">
  <time datetime="2021-11-07T01:52:13.000Z" itemprop="datePublished">2021-11-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Multiview Multitask Gaze Estimation With Deep Convolutional Neural Networks
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>2018 TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS</p>
<p>Dongze Lian, Lina Hu, Weixin Luo, Y anyu Xu, Lixin Duan, Jingyi Y u,Member , IEEE, and Shenghua Gao.</p>
</blockquote>
<p>(1) 评价：基于深度卷积神经网络的<strong>多视图多任务</strong>注视估计</p>
<p>(2)  针对问题：现有的许多方法都是基于单个摄像机的，大多数方法只关注注视点估计或注视方向估计。</p>
<p>(3) 本文的方法：</p>
<p>a.分析了注视点估计和注视方向估计之间的密切关系，并采用<strong>部分共享卷积神经网络结构</strong>来同时估计注视方向和注视点。</p>
<p>b.引入了一种新的<strong>多视角注视跟踪数据集</strong>，该数据集由<strong>不同被试的多视角注视图像组成</strong>。</p>
<p>c.对于注视方向的预测，提出在左右眼注视方向上引入共面约束。</p>
<p>对于注视点的估计，提出引入一个跨视图池模块。</p>
<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211107213710618.png" alt="image-20211107213710618"></p>
<blockquote>
<p>四流输入、四流输出？怎么共享参数?</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://datasets.d2.mpi-inf.mpg.de/MPIIGaze/MPIIGaze.tar.gz">https://datasets.d2.mpi-inf.mpg.de/MPIIGaze/MPIIGaze.tar.gz</a></p>
<h1 id="数据集ShanghaiTechGaze"><a href="#数据集ShanghaiTechGaze" class="headerlink" title="数据集ShanghaiTechGaze"></a>数据集ShanghaiTechGaze</h1><p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211112160847091.png" alt="image-20211112160847091"></p>
<p>设备：使用27英寸的苹果iMac机器作为显示设备。屏幕的宽/高分别为59.77厘米和33.62厘米。然后，屏幕底部部署了三台GoPro Hero 4相机，以捕捉参与者的图像。两台相邻摄像机之间的距离为18.22厘米。</p>
<p>环境：然后，在正常照明条件下，将系统固定在房间的书桌上。为了避免其他移动的物体/人或噪音造成的干扰，房间内保持安静和空无一人，只有一名待命助手除外。</p>
<p>使用大型iMac的第一个原因是，希望在水平和垂直方向上预测更大范围的注视点。相比之下，GazeCapture只预测了手机或平板电脑屏幕内的点。因此，数据集比GazeCapture更具挑战性。</p>
<p>使用iMac的第二个原因是，它的视网膜屏幕有更高的分辨率，以保证像素精度的地面真实;同时，减少了数据采集过程中的眼睛疲劳。</p>
<p>采集过程：要求参与者自由地坐在屏幕前。然后，在灰色背景的屏幕上随机显示一个半径为8像素的白点(作为ground truth)，让参与者用鼠标点击。这样的点击动作可以帮助参与者将注意力吸引到这个点上。然后，记录光标的坐标和动作的时间戳，之后显示光标位置上的蓝点。同时，我们计算白点和蓝点之间的距离。如果距离超过一定的阈值(在我们的设置中是8像素)，则有可能参与者没有盯着白点，因此该数据样本将被丢弃。在采集过程中，GoPro相机被设置为视频模式。根据点击动作的时间戳，我们可以从视频中提取参与者的图像帧。对于每个参与者，在记录数据之前，要求他/她先点击9个点，熟悉数据采集系统。接下来，50个点将在每个环节依次显示给参与者，以进行数据采集。当参与者成功点击上一个点后，屏幕会闪烁，下一个点会显示出来。每个参与者被要求点击12期(总共点击600个点)。在两个周期之间，我们设置了1分钟的休息时间，以避免眼睛疲劳。</p>
<p>我们总共招募了137名学生参与者进行数据收集(年龄在20 — 24岁之间，男性98名，女性39名)。所有参与者视力正常或矫正至正常。在去除白点与蓝点之间距离大于阈值的数据样本后，为每个参与者保留约450-600个点及其对应的眼睛和面孔图像。最后ShanghaiTechGaze数据集由233 796张图像组成。我们进一步使用100个参与者对应的图像作为训练集，其余37个参与者对应的图像作为测试集。</p>
<h2 id="数据组织格式"><a href="#数据组织格式" class="headerlink" title="数据组织格式"></a>数据组织格式</h2><p>—|dataset</p>
<p>——|annotations</p>
<p>———|txtfile</p>
<p>————|test_txt</p>
<p>—————|leftcamera</p>
<p>——————|eyelocation.txt    (images/face_landmarks/leftcamera/00109/00000.mat-images/face_landmarks/leftcamera/00147/00599.mat)21301rows</p>
<p>——————|lefteye.txt    (images/Single_eyes/leftcamera/00109/00000_left.jpg-images/Single_eyes/leftcamera/00147/00599_left.jpg)</p>
<p>——————|righteye.txt    (images/Single_eyes/leftcamera/00109/00000_right.jpg)</p>
<p>—————|middlecamera</p>
<p>——————|eyelocation.txt</p>
<p>——————|lefteye.txt</p>
<p>——————|righteye.txt</p>
<p>—————|rightcamera</p>
<p>——————|eyelocation.txt</p>
<p>——————|lefteye.txt</p>
<p>——————|righteye.txt</p>
<p>—————|gt.txt    (images/coordinate/00109/00000.mat-images/coordinate/00147/00599.mat)</p>
<p>————|train_txt</p>
<p>(images/coordinate/00004/00000.mat-images/coordinate/00108/00599.mat)56631rows</p>
<p>——|images</p>
<p>———|coordinate </p>
<p>————|candidate_index</p>
<p>—————|00000.mat-00599.mat 存放2维数据，真值。</p>
<p>———|face_landmarks（eyelocation，candidate_index，00000.mat-00599.mat）</p>
<p>————|leftcamera存放24维数据</p>
<p>————|middlecamera</p>
<p>————|rightcamera</p>
<p>———|Single_eyes（eye_patch，candidate_index，00000_left.jpg-00599_left.jpg，00000_right.jpg-00599_right.jpg）</p>
<p>————|leftcamera</p>
<p>————|middlecamera</p>
<p>————|rightcamera</p>
<blockquote>
<p>眼睛的landmart位置信息和gt使用.mat格式存储。</p>
</blockquote>
<h1 id="实验code"><a href="#实验code" class="headerlink" title="实验code"></a>实验code</h1><p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/mmcodeStruct.png" alt="image-20211111170143842"></p>
<blockquote>
<p>查看mat格式。能不能清晰的读出来，是否需要下载matlab?</p>
<p>dataloader的__getitem__函数在enumerate部分</p>
</blockquote>
<blockquote>
<p>123行 eyelocation = sio.loadmat(eyelocation_name)[‘eyelocation’]是个24个数字</p>
<p>eyelocation_name = ’/data/ShanghaiTechGaze/images/face_landmarks/leftcamera/00061/00157.mat’</p>
<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211116170548765.png" alt="image-20211116170548765"></p>
</blockquote>
<blockquote>
<p>124行gt = sio.loadmat(gt_name)[‘xy_gt’]是两个数字</p>
<p>gt_name = ‘/data/ShanghaiTechGaze/images/coordinate/00061/00157.mat’</p>
<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211116170844442.png" alt="image-20211116170844442"></p>
<p>数据Normalization 是因为是左眼吗所以这么处理。   </p>
<p>gt[0] -= W_screen / 2 宽</p>
<p>​    gt[1] -= H_screen / 2 高</p>
<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211116171147547.png" alt="image-20211116171147547"></p>
<p>第151行 data, target = (input[‘le’], input[‘re’], input[‘eyelocation’]), input[‘gt’]</p>
<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211116172803224.png" alt="image-20211116172803224"></p>
</blockquote>
<h2 id="multi-view-gaze-master-code-Train-Single-View-ST-py"><a href="#multi-view-gaze-master-code-Train-Single-View-ST-py" class="headerlink" title="multi-view-gaze-master/code/Train_Single_View_ST.py"></a>multi-view-gaze-master/code/Train_Single_View_ST.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GazeImageDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, txt_file, txt_dir, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        </span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">train_loader, model, criterion, optimizer, epoch</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">test_loader, model, criterion, epoch, minimal_error</span>):</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AverageMeter</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, val, n=<span class="number">1</span></span>):</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_error</span>(<span class="params">output, target</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_checkpoint</span>(<span class="params">state, filename=<span class="string">&#x27;checkpoint.pth.tar&#x27;</span></span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adjust_learning_rate</span>(<span class="params">optimizer, epoch</span>):</span></span><br></pre></td></tr></table></figure>

<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/%E5%AE%9E%E9%AA%8C%E5%8F%82%E6%95%B0.png" alt="image-20211115131555168"></p>
<h2 id="multi-view-gaze-master-code-network-gazenet-py"><a href="#multi-view-gaze-master-code-network-gazenet-py" class="headerlink" title="multi-view-gaze-master/code/network/gazenet.py"></a>multi-view-gaze-master/code/network/gazenet.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#选对应的resnet</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">single_view</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line"><span class="comment">#在resnet.py中设置好resnet</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练过程，向前传递参数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, *<span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> self.view == <span class="string">&#x27;single&#x27;</span>:</span><br><span class="line">        out = self.single_view(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>128,512.  128,512. 128,128. 128,1152.</p>
</blockquote>
<h2 id="single-eye-训练思路"><a href="#single-eye-训练思路" class="headerlink" title="single eye 训练思路"></a>single eye 训练思路</h2><p>在每一个epoch里分别训练和测试，每完成一个epoch训练后，保存权重。</p>
<p>每一次训练，每一个batch（即每一个iteration）中，左右眼分别过Resnet34，得到长度为512输出，24维landmark过线性层得到长度为128的输出，之后这3个输出concatenate成1152的输出。再过fc（两次linear），输出。</p>
<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211116212707500.png" alt="image-20211116212707500"></p>
<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211117164429587.png" alt="image-20211117164429587"></p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="路径出错"><a href="#路径出错" class="headerlink" title="路径出错"></a>路径出错</h2><p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks%5CSTpy_101th_row.png" alt="image-20211112150649867"></p>
<p><img src="/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/Users\iszha\AppData\Roaming\Typora\typora-user-images\image-20211119155759306.png" alt="image-20211119155759306"></p>
<blockquote>
<p>眼睛的位置是瞳仁的中心？还是眼周做平均</p>
</blockquote>
<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/dongzelian/multi-view-gaze">dongzelian/multi-view-gaze: Multi-view gaze estimation (github.com)</a></p>
<p>\1)    评价：贡献创新点。</p>
<p>\2)    针对问题：啥情况啥场景。</p>
<p>\3)    本文的目的：可以做到啥。</p>
<p>\4)    实现的方法：</p>
<p>\5)    方法简介</p>
<p>\6)    方法优化</p>
<p>\7)    方法总结‘</p>
<p>\8)    文章存在的问题</p>
<p>\9)    个人的思考</p>
<p>简要的评价，任务，方法的简要描述。关注文章的动机。 </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2021/11/07/Multiview-Multitask-Gaze-Estimation-With-Deep-Convolutional-Neural-Networks/" data-id="ckvtao51l00007cupd8enfwjb" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/11/08/Appearance-Based-Gaze-Estimation-Using-Dilated-Convolutions/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Appearance-Based Gaze Estimation Using Dilated-Convolutions
        
      </div>
    </a>
  
  
    <a href="/2021/11/03/gaze%E7%BB%BC%E8%BF%B0%E6%96%87%E7%AB%A0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">gaze综述文章</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Blog/">Blog</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/">数学建模</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/">课程设计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9D%A2%E8%AF%95%E7%BB%8F%E5%8E%86/">面试经历</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Verilog/" rel="tag">Verilog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/" rel="tag">blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dsp/" rel="tag">dsp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9E%E9%AA%8C/" rel="tag">实验</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/" rel="tag">实验记录</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" rel="tag">数学建模</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" rel="tag">数据处理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" rel="tag">文献阅读</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%9F%E6%B4%BB%E6%80%BB%E7%BB%93/" rel="tag">生活总结</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" rel="tag">论文阅读</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Verilog/" style="font-size: 10px;">Verilog</a> <a href="/tags/blog/" style="font-size: 10px;">blog</a> <a href="/tags/dsp/" style="font-size: 10px;">dsp</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/%E5%AE%9E%E9%AA%8C/" style="font-size: 10px;">实验</a> <a href="/tags/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/" style="font-size: 10px;">实验记录</a> <a href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">数学建模</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" style="font-size: 10px;">数据处理</a> <a href="/tags/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/" style="font-size: 20px;">文献阅读</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 10px;">爬虫</a> <a href="/tags/%E7%94%9F%E6%B4%BB%E6%80%BB%E7%BB%93/" style="font-size: 10px;">生活总结</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 10px;">论文阅读</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/12/31/%E2%80%9D%E9%A3%8E%E6%A0%BC%E9%80%A0%E6%88%90%E7%9A%84%E5%85%B3%E9%94%AE%E7%82%B9%E6%A3%80%E6%B5%8B%E8%AF%AF%E5%B7%AE%E2%80%9C/">风格造成的人脸关键点检测误差</a>
          </li>
        
          <li>
            <a href="/2021/12/28/%E4%BA%BA%E8%84%B8%E5%85%B3%E9%94%AE%E7%82%B9%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86/">人脸关键点检测论文梳理</a>
          </li>
        
          <li>
            <a href="/2021/12/10/EyediapRGBDgaze/">EyediapRGBDgaze</a>
          </li>
        
          <li>
            <a href="/2021/11/19/web3-0/">web3.0</a>
          </li>
        
          <li>
            <a href="/2021/11/18/Few-Shot-Adaptive-Gaze-Estimation/">Few-Shot Adaptive Gaze Estimation</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 iszff<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>